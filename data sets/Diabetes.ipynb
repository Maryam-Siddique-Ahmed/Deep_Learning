{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow.keras import models, layers, optimizers, utils\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # check if any null value is present?\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visulazing OutcomeÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.Outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a # here \"1\" represent diabetic patients.\n",
    "  # \"0\" represent non_diabetic patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x889f1dbbc8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "a.plot(kind=\"bar\",title =\"Outcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1].values\n",
    "Y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, Y_train,Y_test = train_test_split(X,Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how many other missing(zero) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows : 768\n",
      "number of rows missing glucose_conc: 5\n",
      "number of rows missing diastolic_bp: 35\n",
      "number of rows missing insulin: 374\n",
      "number of rows missing bmi: 11\n",
      "number of rows missing diab_pred: 0\n",
      "number of rows missing age: 0\n",
      "number of rows missing skin: 227\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of rows : {0}\".format(len(data)))\n",
    "print(\"number of rows missing glucose_conc: {0}\".format(len(data.loc[data['Glucose'] == 0])))\n",
    "#print(\"number of rows missing glucose_conc: {0}\".format(len(data.loc[data['glucose_conc'] == 0])))\n",
    "print(\"number of rows missing diastolic_bp: {0}\".format(len(data.loc[data['BloodPressure'] == 0])))\n",
    "print(\"number of rows missing insulin: {0}\".format(len(data.loc[data['Insulin'] == 0])))\n",
    "print(\"number of rows missing bmi: {0}\".format(len(data.loc[data['BMI'] == 0])))\n",
    "print(\"number of rows missing diab_pred: {0}\".format(len(data.loc[data['DiabetesPedigreeFunction'] == 0])))\n",
    "print(\"number of rows missing age: {0}\".format(len(data.loc[data['Age'] == 0])))\n",
    "print(\"number of rows missing skin: {0}\".format(len(data.loc[data['SkinThickness'] == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "#fill_values = Imputer(missing_values=0, strategy=\"mean\", axis=0)\n",
    "\n",
    "#X_train = fill_values.fit_transform(X_train)\n",
    "#X_test = fill_values.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(50, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(layers.Dense(40, activation='sigmoid'))\n",
    "    model.add(layers.Dense(1))\n",
    "# compile step\n",
    "    model.compile(optimizer=\"rmsprop\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 537 samples\n",
      "Epoch 1/600\n",
      "537/537 [==============================] - 2s 3ms/sample - loss: 2.7612 - accuracy: 0.6555\n",
      "Epoch 2/600\n",
      "537/537 [==============================] - 0s 103us/sample - loss: 0.9289 - accuracy: 0.6387\n",
      "Epoch 3/600\n",
      "537/537 [==============================] - 0s 95us/sample - loss: 0.6606 - accuracy: 0.6909\n",
      "Epoch 4/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.6598 - accuracy: 0.69 - 0s 95us/sample - loss: 0.6827 - accuracy: 0.7132\n",
      "Epoch 5/600\n",
      "537/537 [==============================] - 0s 97us/sample - loss: 0.6494 - accuracy: 0.6965\n",
      "Epoch 6/600\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.6471 - accuracy: 0.7095\n",
      "Epoch 7/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.6556 - accuracy: 0.6983\n",
      "Epoch 8/600\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.6661 - accuracy: 0.6890\n",
      "Epoch 9/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.6481 - accuracy: 0.6834\n",
      "Epoch 10/600\n",
      "537/537 [==============================] - 0s 93us/sample - loss: 0.5889 - accuracy: 0.6778\n",
      "Epoch 11/600\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.5784 - accuracy: 0.6909\n",
      "Epoch 12/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.5758 - accuracy: 0.7095\n",
      "Epoch 13/600\n",
      "537/537 [==============================] - 0s 91us/sample - loss: 0.5559 - accuracy: 0.7020\n",
      "Epoch 14/600\n",
      "537/537 [==============================] - 0s 97us/sample - loss: 0.5494 - accuracy: 0.6890\n",
      "Epoch 15/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.5695 - accuracy: 0.7114\n",
      "Epoch 16/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.5778 - accuracy: 0.7132\n",
      "Epoch 17/600\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.5924 - accuracy: 0.7039\n",
      "Epoch 18/600\n",
      "537/537 [==============================] - 0s 91us/sample - loss: 0.5710 - accuracy: 0.7039\n",
      "Epoch 19/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.6080 - accuracy: 0.7169\n",
      "Epoch 20/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.5675 - accuracy: 0.6927\n",
      "Epoch 21/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.5459 - accuracy: 0.7225\n",
      "Epoch 22/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.5563 - accuracy: 0.7263\n",
      "Epoch 23/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.5459 - accuracy: 0.7132\n",
      "Epoch 24/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.5341 - accuracy: 0.7300\n",
      "Epoch 25/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.5276 - accuracy: 0.7207\n",
      "Epoch 26/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.5344 - accuracy: 0.7132\n",
      "Epoch 27/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.5402 - accuracy: 0.7169\n",
      "Epoch 28/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.5284 - accuracy: 0.7169\n",
      "Epoch 29/600\n",
      "537/537 [==============================] - 0s 89us/sample - loss: 0.5231 - accuracy: 0.7114\n",
      "Epoch 30/600\n",
      "537/537 [==============================] - 0s 93us/sample - loss: 0.5223 - accuracy: 0.7002\n",
      "Epoch 31/600\n",
      "537/537 [==============================] - 0s 93us/sample - loss: 0.5355 - accuracy: 0.7039\n",
      "Epoch 32/600\n",
      "537/537 [==============================] - 0s 91us/sample - loss: 0.5383 - accuracy: 0.7281\n",
      "Epoch 33/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.5575 - accuracy: 0.7076\n",
      "Epoch 34/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.5144 - accuracy: 0.7412\n",
      "Epoch 35/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.5288 - accuracy: 0.7337\n",
      "Epoch 36/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.5349 - accuracy: 0.7263\n",
      "Epoch 37/600\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.5665 - accuracy: 0.7114\n",
      "Epoch 38/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.5339 - accuracy: 0.7356\n",
      "Epoch 39/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.5175 - accuracy: 0.7188\n",
      "Epoch 40/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.5170 - accuracy: 0.7300\n",
      "Epoch 41/600\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.5171 - accuracy: 0.7207\n",
      "Epoch 42/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.5215 - accuracy: 0.7300\n",
      "Epoch 43/600\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.5085 - accuracy: 0.7467\n",
      "Epoch 44/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.5033 - accuracy: 0.75 - 0s 82us/sample - loss: 0.5238 - accuracy: 0.7151\n",
      "Epoch 45/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.5157 - accuracy: 0.7318\n",
      "Epoch 46/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.5049 - accuracy: 0.7263\n",
      "Epoch 47/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.4972 - accuracy: 0.7393\n",
      "Epoch 48/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.5444 - accuracy: 0.6965\n",
      "Epoch 49/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.5576 - accuracy: 0.7467\n",
      "Epoch 50/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.5128 - accuracy: 0.7207\n",
      "Epoch 51/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.5831 - accuracy: 0.7225\n",
      "Epoch 52/600\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.5076 - accuracy: 0.7132\n",
      "Epoch 53/600\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.5134 - accuracy: 0.7300\n",
      "Epoch 54/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.5534 - accuracy: 0.7561\n",
      "Epoch 55/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4948 - accuracy: 0.7356\n",
      "Epoch 56/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.5282 - accuracy: 0.7300\n",
      "Epoch 57/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.5474 - accuracy: 0.7132\n",
      "Epoch 58/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.5644 - accuracy: 0.7467\n",
      "Epoch 59/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.5023 - accuracy: 0.7374\n",
      "Epoch 60/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.5195 - accuracy: 0.7486\n",
      "Epoch 61/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.5043 - accuracy: 0.7356\n",
      "Epoch 62/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.5137 - accuracy: 0.7412\n",
      "Epoch 63/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.4725 - accuracy: 0.76 - 0s 69us/sample - loss: 0.5487 - accuracy: 0.7263\n",
      "Epoch 64/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.5054 - accuracy: 0.7356\n",
      "Epoch 65/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4973 - accuracy: 0.7486\n",
      "Epoch 66/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.5103 - accuracy: 0.7393\n",
      "Epoch 67/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.5111 - accuracy: 0.7467\n",
      "Epoch 68/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.5199 - accuracy: 0.7356\n",
      "Epoch 69/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.6582 - accuracy: 0.7467\n",
      "Epoch 70/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4880 - accuracy: 0.7505\n",
      "Epoch 71/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4870 - accuracy: 0.7523\n",
      "Epoch 72/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.5317 - accuracy: 0.7188\n",
      "Epoch 73/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.5876 - accuracy: 0.7169\n",
      "Epoch 74/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.5268 - accuracy: 0.7356\n",
      "Epoch 75/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4940 - accuracy: 0.7598\n",
      "Epoch 76/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4803 - accuracy: 0.7654\n",
      "Epoch 77/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4847 - accuracy: 0.7374\n",
      "Epoch 78/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4828 - accuracy: 0.7393\n",
      "Epoch 79/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4749 - accuracy: 0.7561\n",
      "Epoch 80/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.5068 - accuracy: 0.7542\n",
      "Epoch 81/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.4880 - accuracy: 0.7430\n",
      "Epoch 82/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.5089 - accuracy: 0.7412\n",
      "Epoch 83/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.5035 - accuracy: 0.7412\n",
      "Epoch 84/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4833 - accuracy: 0.7412\n",
      "Epoch 85/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.5122 - accuracy: 0.7486\n",
      "Epoch 86/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.4789 - accuracy: 0.7561\n",
      "Epoch 87/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.4994 - accuracy: 0.7244\n",
      "Epoch 88/600\n",
      "537/537 [==============================] - 0s 62us/sample - loss: 0.4770 - accuracy: 0.7486\n",
      "Epoch 89/600\n",
      "537/537 [==============================] - 0s 58us/sample - loss: 0.4979 - accuracy: 0.7616\n",
      "Epoch 90/600\n",
      "537/537 [==============================] - 0s 58us/sample - loss: 0.5942 - accuracy: 0.7300\n",
      "Epoch 91/600\n",
      "537/537 [==============================] - 0s 60us/sample - loss: 0.4796 - accuracy: 0.7579\n",
      "Epoch 92/600\n",
      "537/537 [==============================] - 0s 60us/sample - loss: 0.4746 - accuracy: 0.7728\n",
      "Epoch 93/600\n",
      "537/537 [==============================] - 0s 58us/sample - loss: 0.4867 - accuracy: 0.7542\n",
      "Epoch 94/600\n",
      "537/537 [==============================] - 0s 62us/sample - loss: 0.4698 - accuracy: 0.7765\n",
      "Epoch 95/600\n",
      "537/537 [==============================] - 0s 60us/sample - loss: 0.4790 - accuracy: 0.7654\n",
      "Epoch 96/600\n",
      "537/537 [==============================] - 0s 62us/sample - loss: 0.4626 - accuracy: 0.7542\n",
      "Epoch 97/600\n",
      "537/537 [==============================] - 0s 84us/sample - loss: 0.5741 - accuracy: 0.7449\n",
      "Epoch 98/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4715 - accuracy: 0.7598\n",
      "Epoch 99/600\n",
      "537/537 [==============================] - 0s 91us/sample - loss: 0.4888 - accuracy: 0.7318\n",
      "Epoch 100/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.5042 - accuracy: 0.7542\n",
      "Epoch 101/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4878 - accuracy: 0.7635\n",
      "Epoch 102/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4801 - accuracy: 0.7579\n",
      "Epoch 103/600\n",
      "537/537 [==============================] - 0s 136us/sample - loss: 0.4893 - accuracy: 0.7467\n",
      "Epoch 104/600\n",
      "537/537 [==============================] - 0s 291us/sample - loss: 0.4928 - accuracy: 0.7542\n",
      "Epoch 105/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4682 - accuracy: 0.7654\n",
      "Epoch 106/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4824 - accuracy: 0.7467\n",
      "Epoch 107/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.4608 - accuracy: 0.7709\n",
      "Epoch 108/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4588 - accuracy: 0.7654\n",
      "Epoch 109/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4727 - accuracy: 0.7672\n",
      "Epoch 110/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4651 - accuracy: 0.7654\n",
      "Epoch 111/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4599 - accuracy: 0.7635\n",
      "Epoch 112/600\n",
      "537/537 [==============================] - 0s 123us/sample - loss: 0.4736 - accuracy: 0.7561\n",
      "Epoch 113/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4875 - accuracy: 0.7579\n",
      "Epoch 114/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.5095 - accuracy: 0.7579\n",
      "Epoch 115/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.4656 - accuracy: 0.7709\n",
      "Epoch 116/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4689 - accuracy: 0.7635\n",
      "Epoch 117/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4597 - accuracy: 0.7579\n",
      "Epoch 118/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4586 - accuracy: 0.7654\n",
      "Epoch 119/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.5157 - accuracy: 0.7430\n",
      "Epoch 120/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4525 - accuracy: 0.7523\n",
      "Epoch 121/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4982 - accuracy: 0.7579\n",
      "Epoch 122/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4688 - accuracy: 0.7598\n",
      "Epoch 123/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4898 - accuracy: 0.7654\n",
      "Epoch 124/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.4671 - accuracy: 0.7635\n",
      "Epoch 125/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4686 - accuracy: 0.7486\n",
      "Epoch 126/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4867 - accuracy: 0.7765\n",
      "Epoch 127/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4490 - accuracy: 0.7672\n",
      "Epoch 128/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.5125 - accuracy: 0.7412\n",
      "Epoch 129/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.81 - 0s 67us/sample - loss: 0.4578 - accuracy: 0.7672\n",
      "Epoch 130/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4587 - accuracy: 0.7523\n",
      "Epoch 131/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4501 - accuracy: 0.7933\n",
      "Epoch 132/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4842 - accuracy: 0.7635\n",
      "Epoch 133/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4439 - accuracy: 0.7598\n",
      "Epoch 134/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4582 - accuracy: 0.7561\n",
      "Epoch 135/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.4503 - accuracy: 0.7803\n",
      "Epoch 136/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4777 - accuracy: 0.7877\n",
      "Epoch 137/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4543 - accuracy: 0.7654\n",
      "Epoch 138/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4400 - accuracy: 0.7803\n",
      "Epoch 139/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4689 - accuracy: 0.7523\n",
      "Epoch 140/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4596 - accuracy: 0.7709\n",
      "Epoch 141/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4551 - accuracy: 0.7672\n",
      "Epoch 142/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4437 - accuracy: 0.7765\n",
      "Epoch 143/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4512 - accuracy: 0.7691\n",
      "Epoch 144/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4587 - accuracy: 0.7561\n",
      "Epoch 145/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4449 - accuracy: 0.7728\n",
      "Epoch 146/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4762 - accuracy: 0.7542\n",
      "Epoch 147/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4395 - accuracy: 0.7803\n",
      "Epoch 148/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4377 - accuracy: 0.7952\n",
      "Epoch 149/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.4571 - accuracy: 0.7616\n",
      "Epoch 150/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4507 - accuracy: 0.7821\n",
      "Epoch 151/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4391 - accuracy: 0.7914\n",
      "Epoch 152/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4706 - accuracy: 0.7654\n",
      "Epoch 153/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.5283 - accuracy: 0.7896\n",
      "Epoch 154/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 67us/sample - loss: 0.5698 - accuracy: 0.7393\n",
      "Epoch 155/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4403 - accuracy: 0.7840\n",
      "Epoch 156/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4633 - accuracy: 0.7691\n",
      "Epoch 157/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.4667 - accuracy: 0.74 - 0s 69us/sample - loss: 0.4517 - accuracy: 0.7691\n",
      "Epoch 158/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4348 - accuracy: 0.7803\n",
      "Epoch 159/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4450 - accuracy: 0.7747\n",
      "Epoch 160/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.4963 - accuracy: 0.7430\n",
      "Epoch 161/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4464 - accuracy: 0.7877\n",
      "Epoch 162/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4332 - accuracy: 0.8007\n",
      "Epoch 163/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.4777 - accuracy: 0.7803\n",
      "Epoch 164/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4479 - accuracy: 0.7654\n",
      "Epoch 165/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4316 - accuracy: 0.7877\n",
      "Epoch 166/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.4447 - accuracy: 0.7709\n",
      "Epoch 167/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4363 - accuracy: 0.7747\n",
      "Epoch 168/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4278 - accuracy: 0.7970\n",
      "Epoch 169/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.5824 - accuracy: 0.7579\n",
      "Epoch 170/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4362 - accuracy: 0.7858\n",
      "Epoch 171/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4675 - accuracy: 0.7467\n",
      "Epoch 172/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4317 - accuracy: 0.7803\n",
      "Epoch 173/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4333 - accuracy: 0.7914\n",
      "Epoch 174/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4219 - accuracy: 0.7914\n",
      "Epoch 175/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4406 - accuracy: 0.7709\n",
      "Epoch 176/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.5533 - accuracy: 0.7523\n",
      "Epoch 177/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4212 - accuracy: 0.7821\n",
      "Epoch 178/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.4833 - accuracy: 0.7877\n",
      "Epoch 179/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4271 - accuracy: 0.7989\n",
      "Epoch 180/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.4382 - accuracy: 0.7691\n",
      "Epoch 181/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4300 - accuracy: 0.7896\n",
      "Epoch 182/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4317 - accuracy: 0.7709\n",
      "Epoch 183/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4670 - accuracy: 0.7840\n",
      "Epoch 184/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4621 - accuracy: 0.7654\n",
      "Epoch 185/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4865 - accuracy: 0.7914\n",
      "Epoch 186/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4262 - accuracy: 0.7933\n",
      "Epoch 187/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.4687 - accuracy: 0.7598\n",
      "Epoch 188/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4195 - accuracy: 0.7896\n",
      "Epoch 189/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4577 - accuracy: 0.7561\n",
      "Epoch 190/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4213 - accuracy: 0.8026\n",
      "Epoch 191/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4234 - accuracy: 0.7877\n",
      "Epoch 192/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4463 - accuracy: 0.7840\n",
      "Epoch 193/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4185 - accuracy: 0.7784\n",
      "Epoch 194/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4211 - accuracy: 0.7877\n",
      "Epoch 195/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4698 - accuracy: 0.7840\n",
      "Epoch 196/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4490 - accuracy: 0.7691\n",
      "Epoch 197/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4726 - accuracy: 0.7486\n",
      "Epoch 198/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4302 - accuracy: 0.7952\n",
      "Epoch 199/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4335 - accuracy: 0.8007\n",
      "Epoch 200/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4231 - accuracy: 0.7747\n",
      "Epoch 201/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4495 - accuracy: 0.7747\n",
      "Epoch 202/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4222 - accuracy: 0.7691\n",
      "Epoch 203/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4448 - accuracy: 0.7821\n",
      "Epoch 204/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4297 - accuracy: 0.7728\n",
      "Epoch 205/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4457 - accuracy: 0.7765\n",
      "Epoch 206/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4933 - accuracy: 0.7579\n",
      "Epoch 207/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4825 - accuracy: 0.7654\n",
      "Epoch 208/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4154 - accuracy: 0.7896\n",
      "Epoch 209/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4123 - accuracy: 0.8045\n",
      "Epoch 210/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4911 - accuracy: 0.7561\n",
      "Epoch 211/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4353 - accuracy: 0.7747\n",
      "Epoch 212/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4238 - accuracy: 0.7877\n",
      "Epoch 213/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4356 - accuracy: 0.7728\n",
      "Epoch 214/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4145 - accuracy: 0.8007\n",
      "Epoch 215/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4544 - accuracy: 0.7523\n",
      "Epoch 216/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.4151 - accuracy: 0.7896\n",
      "Epoch 217/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4352 - accuracy: 0.7858\n",
      "Epoch 218/600\n",
      "537/537 [==============================] - 0s 62us/sample - loss: 0.4290 - accuracy: 0.7970\n",
      "Epoch 219/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4397 - accuracy: 0.7858\n",
      "Epoch 220/600\n",
      "537/537 [==============================] - 0s 63us/sample - loss: 0.4401 - accuracy: 0.7877\n",
      "Epoch 221/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4351 - accuracy: 0.7728\n",
      "Epoch 222/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.4143 - accuracy: 0.7989\n",
      "Epoch 223/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4305 - accuracy: 0.7821\n",
      "Epoch 224/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4077 - accuracy: 0.8082\n",
      "Epoch 225/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4145 - accuracy: 0.7858\n",
      "Epoch 226/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4687 - accuracy: 0.7561\n",
      "Epoch 227/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4326 - accuracy: 0.7821\n",
      "Epoch 228/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4196 - accuracy: 0.7970\n",
      "Epoch 229/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4297 - accuracy: 0.7803\n",
      "Epoch 230/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4301 - accuracy: 0.7952\n",
      "Epoch 231/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4840 - accuracy: 0.7914\n",
      "Epoch 232/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.4215 - accuracy: 0.7970\n",
      "Epoch 233/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.6061 - accuracy: 0.7542\n",
      "Epoch 234/600\n",
      "537/537 [==============================] - 0s 63us/sample - loss: 0.4382 - accuracy: 0.7803\n",
      "Epoch 235/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4251 - accuracy: 0.7803\n",
      "Epoch 236/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4204 - accuracy: 0.7914\n",
      "Epoch 237/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4145 - accuracy: 0.8007\n",
      "Epoch 238/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4217 - accuracy: 0.7933\n",
      "Epoch 239/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4280 - accuracy: 0.7691\n",
      "Epoch 240/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.4039 - accuracy: 0.7896\n",
      "Epoch 241/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4389 - accuracy: 0.7896\n",
      "Epoch 242/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4092 - accuracy: 0.7989\n",
      "Epoch 243/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4060 - accuracy: 0.7989\n",
      "Epoch 244/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4459 - accuracy: 0.8082\n",
      "Epoch 245/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4120 - accuracy: 0.7970\n",
      "Epoch 246/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4191 - accuracy: 0.8026\n",
      "Epoch 247/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4423 - accuracy: 0.7840\n",
      "Epoch 248/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4255 - accuracy: 0.7933\n",
      "Epoch 249/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.4128 - accuracy: 0.77 - 0s 71us/sample - loss: 0.4018 - accuracy: 0.8045\n",
      "Epoch 250/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4594 - accuracy: 0.7803\n",
      "Epoch 251/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4183 - accuracy: 0.7821\n",
      "Epoch 252/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4495 - accuracy: 0.7654\n",
      "Epoch 253/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4015 - accuracy: 0.8026\n",
      "Epoch 254/600\n",
      "537/537 [==============================] - 0s 63us/sample - loss: 0.4141 - accuracy: 0.7821\n",
      "Epoch 255/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4287 - accuracy: 0.7579\n",
      "Epoch 256/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.4271 - accuracy: 0.7970\n",
      "Epoch 257/600\n",
      "537/537 [==============================] - 0s 88us/sample - loss: 0.4593 - accuracy: 0.7765\n",
      "Epoch 258/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4200 - accuracy: 0.7989\n",
      "Epoch 259/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4150 - accuracy: 0.7933\n",
      "Epoch 260/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4079 - accuracy: 0.7877\n",
      "Epoch 261/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4052 - accuracy: 0.7896\n",
      "Epoch 262/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4058 - accuracy: 0.7952\n",
      "Epoch 263/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4082 - accuracy: 0.7728\n",
      "Epoch 264/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4540 - accuracy: 0.7598\n",
      "Epoch 265/600\n",
      "537/537 [==============================] - 0s 153us/sample - loss: 0.4086 - accuracy: 0.7896\n",
      "Epoch 266/600\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.4395 - accuracy: 0.7896\n",
      "Epoch 267/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4186 - accuracy: 0.7821\n",
      "Epoch 268/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4316 - accuracy: 0.7803\n",
      "Epoch 269/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3991 - accuracy: 0.8082\n",
      "Epoch 270/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4825 - accuracy: 0.7840\n",
      "Epoch 271/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4020 - accuracy: 0.7952\n",
      "Epoch 272/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4122 - accuracy: 0.8082\n",
      "Epoch 273/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4012 - accuracy: 0.7914\n",
      "Epoch 274/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.4118 - accuracy: 0.7914\n",
      "Epoch 275/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4108 - accuracy: 0.8119\n",
      "Epoch 276/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.4093 - accuracy: 0.7821\n",
      "Epoch 277/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4178 - accuracy: 0.7933\n",
      "Epoch 278/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4193 - accuracy: 0.7765\n",
      "Epoch 279/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.4146 - accuracy: 0.7877\n",
      "Epoch 280/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4022 - accuracy: 0.8082\n",
      "Epoch 281/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.3988 - accuracy: 0.7989\n",
      "Epoch 282/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4000 - accuracy: 0.8082\n",
      "Epoch 283/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4298 - accuracy: 0.7858\n",
      "Epoch 284/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4170 - accuracy: 0.7877\n",
      "Epoch 285/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4434 - accuracy: 0.7803\n",
      "Epoch 286/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3901 - accuracy: 0.8175\n",
      "Epoch 287/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4385 - accuracy: 0.7709\n",
      "Epoch 288/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4095 - accuracy: 0.7896\n",
      "Epoch 289/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.3919 - accuracy: 0.8101\n",
      "Epoch 290/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4237 - accuracy: 0.7821\n",
      "Epoch 291/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4149 - accuracy: 0.7914\n",
      "Epoch 292/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4282 - accuracy: 0.7952\n",
      "Epoch 293/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4151 - accuracy: 0.7821\n",
      "Epoch 294/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4004 - accuracy: 0.8101\n",
      "Epoch 295/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4351 - accuracy: 0.7858\n",
      "Epoch 296/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4427 - accuracy: 0.7896\n",
      "Epoch 297/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.4617 - accuracy: 0.72 - 0s 71us/sample - loss: 0.3937 - accuracy: 0.7952\n",
      "Epoch 298/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3963 - accuracy: 0.7840\n",
      "Epoch 299/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4195 - accuracy: 0.8082\n",
      "Epoch 300/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4019 - accuracy: 0.7896\n",
      "Epoch 301/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3954 - accuracy: 0.7933\n",
      "Epoch 302/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4051 - accuracy: 0.7970\n",
      "Epoch 303/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4027 - accuracy: 0.7952\n",
      "Epoch 304/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4146 - accuracy: 0.7877\n",
      "Epoch 305/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3940 - accuracy: 0.8045\n",
      "Epoch 306/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.3968 - accuracy: 0.8063\n",
      "Epoch 307/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 71us/sample - loss: 0.5310 - accuracy: 0.7728\n",
      "Epoch 308/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.4142 - accuracy: 0.7952\n",
      "Epoch 309/600\n",
      "537/537 [==============================] - 0s 63us/sample - loss: 0.4032 - accuracy: 0.7803\n",
      "Epoch 310/600\n",
      "537/537 [==============================] - 0s 86us/sample - loss: 0.3981 - accuracy: 0.7896\n",
      "Epoch 311/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4245 - accuracy: 0.8007\n",
      "Epoch 312/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3937 - accuracy: 0.8026\n",
      "Epoch 313/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3880 - accuracy: 0.8045\n",
      "Epoch 314/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.4085 - accuracy: 0.7877\n",
      "Epoch 315/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.4135 - accuracy: 0.8063\n",
      "Epoch 316/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4148 - accuracy: 0.7858\n",
      "Epoch 317/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4072 - accuracy: 0.7877\n",
      "Epoch 318/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4121 - accuracy: 0.7914\n",
      "Epoch 319/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4207 - accuracy: 0.7877\n",
      "Epoch 320/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4626 - accuracy: 0.7933\n",
      "Epoch 321/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4082 - accuracy: 0.8063\n",
      "Epoch 322/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3929 - accuracy: 0.8045\n",
      "Epoch 323/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3959 - accuracy: 0.8063\n",
      "Epoch 324/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3927 - accuracy: 0.8138\n",
      "Epoch 325/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3959 - accuracy: 0.8007\n",
      "Epoch 326/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3948 - accuracy: 0.8007\n",
      "Epoch 327/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3930 - accuracy: 0.7989\n",
      "Epoch 328/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4080 - accuracy: 0.8045\n",
      "Epoch 329/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3866 - accuracy: 0.7970\n",
      "Epoch 330/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3814 - accuracy: 0.8007\n",
      "Epoch 331/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4412 - accuracy: 0.8026\n",
      "Epoch 332/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4501 - accuracy: 0.7989\n",
      "Epoch 333/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4105 - accuracy: 0.8045\n",
      "Epoch 334/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4421 - accuracy: 0.7896\n",
      "Epoch 335/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.4237 - accuracy: 0.8007\n",
      "Epoch 336/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3796 - accuracy: 0.8138\n",
      "Epoch 337/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3842 - accuracy: 0.8101\n",
      "Epoch 338/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3894 - accuracy: 0.8101\n",
      "Epoch 339/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4285 - accuracy: 0.8045\n",
      "Epoch 340/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4305 - accuracy: 0.7840\n",
      "Epoch 341/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4001 - accuracy: 0.7896\n",
      "Epoch 342/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3871 - accuracy: 0.8082\n",
      "Epoch 343/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3806 - accuracy: 0.8063\n",
      "Epoch 344/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4080 - accuracy: 0.7933\n",
      "Epoch 345/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3839 - accuracy: 0.7970\n",
      "Epoch 346/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3766 - accuracy: 0.8138\n",
      "Epoch 347/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4037 - accuracy: 0.7952\n",
      "Epoch 348/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.3887 - accuracy: 0.7989\n",
      "Epoch 349/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4137 - accuracy: 0.7933\n",
      "Epoch 350/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3867 - accuracy: 0.8007\n",
      "Epoch 351/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4527 - accuracy: 0.7858\n",
      "Epoch 352/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3939 - accuracy: 0.7933\n",
      "Epoch 353/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4194 - accuracy: 0.7709\n",
      "Epoch 354/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3822 - accuracy: 0.7896\n",
      "Epoch 355/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3860 - accuracy: 0.7877\n",
      "Epoch 356/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3969 - accuracy: 0.8063\n",
      "Epoch 357/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3947 - accuracy: 0.7970\n",
      "Epoch 358/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3836 - accuracy: 0.8250\n",
      "Epoch 359/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3823 - accuracy: 0.7914\n",
      "Epoch 360/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4185 - accuracy: 0.7858\n",
      "Epoch 361/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4008 - accuracy: 0.8231\n",
      "Epoch 362/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4077 - accuracy: 0.7933\n",
      "Epoch 363/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3872 - accuracy: 0.8045\n",
      "Epoch 364/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3807 - accuracy: 0.8026\n",
      "Epoch 365/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3878 - accuracy: 0.8082\n",
      "Epoch 366/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4105 - accuracy: 0.7896\n",
      "Epoch 367/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.3820 - accuracy: 0.8026\n",
      "Epoch 368/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3842 - accuracy: 0.8119\n",
      "Epoch 369/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3886 - accuracy: 0.8082\n",
      "Epoch 370/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.4168 - accuracy: 0.76 - 0s 71us/sample - loss: 0.3751 - accuracy: 0.7933\n",
      "Epoch 371/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4259 - accuracy: 0.7970\n",
      "Epoch 372/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4185 - accuracy: 0.7821\n",
      "Epoch 373/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3835 - accuracy: 0.7989\n",
      "Epoch 374/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3925 - accuracy: 0.7914\n",
      "Epoch 375/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3815 - accuracy: 0.7896\n",
      "Epoch 376/600\n",
      "537/537 [==============================] - 0s 63us/sample - loss: 0.3629 - accuracy: 0.8156\n",
      "Epoch 377/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4389 - accuracy: 0.8007\n",
      "Epoch 378/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3822 - accuracy: 0.8156\n",
      "Epoch 379/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3717 - accuracy: 0.8268\n",
      "Epoch 380/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3926 - accuracy: 0.7933\n",
      "Epoch 381/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3867 - accuracy: 0.7896\n",
      "Epoch 382/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3875 - accuracy: 0.8007\n",
      "Epoch 383/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3758 - accuracy: 0.7989\n",
      "Epoch 384/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3647 - accuracy: 0.8212\n",
      "Epoch 385/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3849 - accuracy: 0.8007\n",
      "Epoch 386/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4623 - accuracy: 0.7952\n",
      "Epoch 387/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4250 - accuracy: 0.7840\n",
      "Epoch 388/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3787 - accuracy: 0.8063\n",
      "Epoch 389/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3684 - accuracy: 0.8082\n",
      "Epoch 390/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3737 - accuracy: 0.8026\n",
      "Epoch 391/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3851 - accuracy: 0.8231\n",
      "Epoch 392/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3824 - accuracy: 0.7989\n",
      "Epoch 393/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3689 - accuracy: 0.8212\n",
      "Epoch 394/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3838 - accuracy: 0.8082\n",
      "Epoch 395/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3799 - accuracy: 0.8194\n",
      "Epoch 396/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4317 - accuracy: 0.7914\n",
      "Epoch 397/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3744 - accuracy: 0.8007\n",
      "Epoch 398/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3780 - accuracy: 0.8007\n",
      "Epoch 399/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4269 - accuracy: 0.7896\n",
      "Epoch 400/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3739 - accuracy: 0.8101\n",
      "Epoch 401/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3750 - accuracy: 0.8138\n",
      "Epoch 402/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.4458 - accuracy: 0.82 - 0s 69us/sample - loss: 0.5057 - accuracy: 0.8045\n",
      "Epoch 403/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4823 - accuracy: 0.7747\n",
      "Epoch 404/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4329 - accuracy: 0.8045\n",
      "Epoch 405/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3697 - accuracy: 0.8138\n",
      "Epoch 406/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3755 - accuracy: 0.8007\n",
      "Epoch 407/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3762 - accuracy: 0.8082\n",
      "Epoch 408/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3642 - accuracy: 0.8287\n",
      "Epoch 409/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4301 - accuracy: 0.8082\n",
      "Epoch 410/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3822 - accuracy: 0.8007\n",
      "Epoch 411/600\n",
      "537/537 [==============================] - 0s 93us/sample - loss: 0.3671 - accuracy: 0.8119\n",
      "Epoch 412/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3759 - accuracy: 0.8082\n",
      "Epoch 413/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3815 - accuracy: 0.8007\n",
      "Epoch 414/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4217 - accuracy: 0.7970\n",
      "Epoch 415/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3654 - accuracy: 0.8212\n",
      "Epoch 416/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3697 - accuracy: 0.8175\n",
      "Epoch 417/600\n",
      "537/537 [==============================] - 0s 63us/sample - loss: 0.3900 - accuracy: 0.8082\n",
      "Epoch 418/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3741 - accuracy: 0.8212\n",
      "Epoch 419/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.3721 - accuracy: 0.8194\n",
      "Epoch 420/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3845 - accuracy: 0.8026\n",
      "Epoch 421/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3689 - accuracy: 0.8194\n",
      "Epoch 422/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3725 - accuracy: 0.8119\n",
      "Epoch 423/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3751 - accuracy: 0.8082\n",
      "Epoch 424/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4005 - accuracy: 0.7914\n",
      "Epoch 425/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4101 - accuracy: 0.8007\n",
      "Epoch 426/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3687 - accuracy: 0.8138\n",
      "Epoch 427/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3508 - accuracy: 0.8194\n",
      "Epoch 428/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3659 - accuracy: 0.8063\n",
      "Epoch 429/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3834 - accuracy: 0.8063\n",
      "Epoch 430/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3653 - accuracy: 0.8175\n",
      "Epoch 431/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3610 - accuracy: 0.8082\n",
      "Epoch 432/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4025 - accuracy: 0.7989\n",
      "Epoch 433/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3958 - accuracy: 0.8045\n",
      "Epoch 434/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3726 - accuracy: 0.8026\n",
      "Epoch 435/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3569 - accuracy: 0.8194\n",
      "Epoch 436/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3620 - accuracy: 0.8138\n",
      "Epoch 437/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4004 - accuracy: 0.7970\n",
      "Epoch 438/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3537 - accuracy: 0.8324\n",
      "Epoch 439/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3827 - accuracy: 0.8101\n",
      "Epoch 440/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3757 - accuracy: 0.8212\n",
      "Epoch 441/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3579 - accuracy: 0.8175\n",
      "Epoch 442/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3627 - accuracy: 0.8082\n",
      "Epoch 443/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3589 - accuracy: 0.8082\n",
      "Epoch 444/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3889 - accuracy: 0.7840\n",
      "Epoch 445/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3615 - accuracy: 0.8287\n",
      "Epoch 446/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3756 - accuracy: 0.8175\n",
      "Epoch 447/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3799 - accuracy: 0.8063\n",
      "Epoch 448/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3608 - accuracy: 0.8250\n",
      "Epoch 449/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3600 - accuracy: 0.8138\n",
      "Epoch 450/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.3850 - accuracy: 0.8101\n",
      "Epoch 451/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3766 - accuracy: 0.8082\n",
      "Epoch 452/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4128 - accuracy: 0.7970\n",
      "Epoch 453/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4411 - accuracy: 0.8007\n",
      "Epoch 454/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3720 - accuracy: 0.8082\n",
      "Epoch 455/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3454 - accuracy: 0.8417\n",
      "Epoch 456/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3613 - accuracy: 0.8138\n",
      "Epoch 457/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3657 - accuracy: 0.8212\n",
      "Epoch 458/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3559 - accuracy: 0.8156\n",
      "Epoch 459/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.3552 - accuracy: 0.8194\n",
      "Epoch 460/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3810 - accuracy: 0.8045\n",
      "Epoch 461/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3617 - accuracy: 0.8175\n",
      "Epoch 462/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.80 - 0s 73us/sample - loss: 0.3686 - accuracy: 0.8045\n",
      "Epoch 463/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3455 - accuracy: 0.8175\n",
      "Epoch 464/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4175 - accuracy: 0.8156\n",
      "Epoch 465/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3657 - accuracy: 0.8101\n",
      "Epoch 466/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3572 - accuracy: 0.8194\n",
      "Epoch 467/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.4156 - accuracy: 0.8138\n",
      "Epoch 468/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3600 - accuracy: 0.8305\n",
      "Epoch 469/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3560 - accuracy: 0.8194\n",
      "Epoch 470/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3519 - accuracy: 0.8231\n",
      "Epoch 471/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3863 - accuracy: 0.8045\n",
      "Epoch 472/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.3536 - accuracy: 0.8101\n",
      "Epoch 473/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3465 - accuracy: 0.8250\n",
      "Epoch 474/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.3502 - accuracy: 0.8343\n",
      "Epoch 475/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3488 - accuracy: 0.8250\n",
      "Epoch 476/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3411 - accuracy: 0.8305\n",
      "Epoch 477/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3807 - accuracy: 0.7952\n",
      "Epoch 478/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4074 - accuracy: 0.7989\n",
      "Epoch 479/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3541 - accuracy: 0.8268\n",
      "Epoch 480/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3522 - accuracy: 0.8212\n",
      "Epoch 481/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3609 - accuracy: 0.8361\n",
      "Epoch 482/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4060 - accuracy: 0.8194\n",
      "Epoch 483/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3396 - accuracy: 0.8231\n",
      "Epoch 484/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.3840 - accuracy: 0.8268\n",
      "Epoch 485/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3506 - accuracy: 0.8287\n",
      "Epoch 486/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3508 - accuracy: 0.8175\n",
      "Epoch 487/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.3674 - accuracy: 0.78 - 0s 71us/sample - loss: 0.3594 - accuracy: 0.7970\n",
      "Epoch 488/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4482 - accuracy: 0.8212\n",
      "Epoch 489/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3745 - accuracy: 0.8194\n",
      "Epoch 490/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3601 - accuracy: 0.8231\n",
      "Epoch 491/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3355 - accuracy: 0.8324\n",
      "Epoch 492/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4115 - accuracy: 0.8175\n",
      "Epoch 493/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3594 - accuracy: 0.8268\n",
      "Epoch 494/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4555 - accuracy: 0.7952\n",
      "Epoch 495/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3504 - accuracy: 0.8194\n",
      "Epoch 496/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3569 - accuracy: 0.8007\n",
      "Epoch 497/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3653 - accuracy: 0.8156\n",
      "Epoch 498/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3451 - accuracy: 0.8268\n",
      "Epoch 499/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3573 - accuracy: 0.8305\n",
      "Epoch 500/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.77 - 0s 73us/sample - loss: 0.3712 - accuracy: 0.8026\n",
      "Epoch 501/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4402 - accuracy: 0.8101\n",
      "Epoch 502/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3473 - accuracy: 0.8324\n",
      "Epoch 503/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4143 - accuracy: 0.7970\n",
      "Epoch 504/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3409 - accuracy: 0.8324\n",
      "Epoch 505/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.3614 - accuracy: 0.79 - 0s 73us/sample - loss: 0.3453 - accuracy: 0.8156\n",
      "Epoch 506/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.3880 - accuracy: 0.8194\n",
      "Epoch 507/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.3436 - accuracy: 0.8268\n",
      "Epoch 508/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.3487 - accuracy: 0.8156\n",
      "Epoch 509/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3446 - accuracy: 0.8380\n",
      "Epoch 510/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.3639 - accuracy: 0.8324\n",
      "Epoch 511/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3418 - accuracy: 0.8212\n",
      "Epoch 512/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3488 - accuracy: 0.8063\n",
      "Epoch 513/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3458 - accuracy: 0.8287\n",
      "Epoch 514/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3375 - accuracy: 0.8268\n",
      "Epoch 515/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3789 - accuracy: 0.8250\n",
      "Epoch 516/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3361 - accuracy: 0.8454\n",
      "Epoch 517/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.4483 - accuracy: 0.7765\n",
      "Epoch 518/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3507 - accuracy: 0.8343\n",
      "Epoch 519/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3369 - accuracy: 0.8399\n",
      "Epoch 520/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3349 - accuracy: 0.8343\n",
      "Epoch 521/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3389 - accuracy: 0.8175\n",
      "Epoch 522/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.3614 - accuracy: 0.8194\n",
      "Epoch 523/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3497 - accuracy: 0.8305\n",
      "Epoch 524/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3856 - accuracy: 0.8082\n",
      "Epoch 525/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3304 - accuracy: 0.8361\n",
      "Epoch 526/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3387 - accuracy: 0.8063\n",
      "Epoch 527/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3980 - accuracy: 0.8026\n",
      "Epoch 528/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3417 - accuracy: 0.8324\n",
      "Epoch 529/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3827 - accuracy: 0.8305\n",
      "Epoch 530/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3847 - accuracy: 0.8250\n",
      "Epoch 531/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3293 - accuracy: 0.8212\n",
      "Epoch 532/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3508 - accuracy: 0.8138\n",
      "Epoch 533/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3558 - accuracy: 0.8324\n",
      "Epoch 534/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3396 - accuracy: 0.8380\n",
      "Epoch 535/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.3330 - accuracy: 0.8250\n",
      "Epoch 536/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3378 - accuracy: 0.8343\n",
      "Epoch 537/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4038 - accuracy: 0.8194\n",
      "Epoch 538/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3472 - accuracy: 0.8268\n",
      "Epoch 539/600\n",
      "537/537 [==============================] - ETA: 0s - loss: 0.3303 - accuracy: 0.82 - 0s 71us/sample - loss: 0.3291 - accuracy: 0.8287\n",
      "Epoch 540/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3567 - accuracy: 0.8119\n",
      "Epoch 541/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.4712 - accuracy: 0.7654\n",
      "Epoch 542/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.3380 - accuracy: 0.8268\n",
      "Epoch 543/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3191 - accuracy: 0.8343\n",
      "Epoch 544/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3367 - accuracy: 0.8343\n",
      "Epoch 545/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3253 - accuracy: 0.8417\n",
      "Epoch 546/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3464 - accuracy: 0.8194\n",
      "Epoch 547/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3746 - accuracy: 0.8250\n",
      "Epoch 548/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.4123 - accuracy: 0.8026\n",
      "Epoch 549/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3845 - accuracy: 0.7970\n",
      "Epoch 550/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3385 - accuracy: 0.8287\n",
      "Epoch 551/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.3598 - accuracy: 0.8119\n",
      "Epoch 552/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3333 - accuracy: 0.8287\n",
      "Epoch 553/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3870 - accuracy: 0.8045\n",
      "Epoch 554/600\n",
      "537/537 [==============================] - 0s 80us/sample - loss: 0.3389 - accuracy: 0.8268\n",
      "Epoch 555/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3856 - accuracy: 0.8343\n",
      "Epoch 556/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3430 - accuracy: 0.8324\n",
      "Epoch 557/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3550 - accuracy: 0.8101\n",
      "Epoch 558/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3584 - accuracy: 0.8324\n",
      "Epoch 559/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3366 - accuracy: 0.8417\n",
      "Epoch 560/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.3605 - accuracy: 0.8250\n",
      "Epoch 561/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3373 - accuracy: 0.8343\n",
      "Epoch 562/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3635 - accuracy: 0.8250\n",
      "Epoch 563/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3168 - accuracy: 0.8547\n",
      "Epoch 564/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3435 - accuracy: 0.8231\n",
      "Epoch 565/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3444 - accuracy: 0.8175\n",
      "Epoch 566/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3437 - accuracy: 0.8175\n",
      "Epoch 567/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3363 - accuracy: 0.8287\n",
      "Epoch 568/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3417 - accuracy: 0.8380\n",
      "Epoch 569/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.3558 - accuracy: 0.8138\n",
      "Epoch 570/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.3343 - accuracy: 0.8436\n",
      "Epoch 571/600\n",
      "537/537 [==============================] - 0s 82us/sample - loss: 0.3345 - accuracy: 0.8305\n",
      "Epoch 572/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3323 - accuracy: 0.8399\n",
      "Epoch 573/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3797 - accuracy: 0.8305\n",
      "Epoch 574/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3237 - accuracy: 0.8305\n",
      "Epoch 575/600\n",
      "537/537 [==============================] - 0s 78us/sample - loss: 0.3262 - accuracy: 0.8324\n",
      "Epoch 576/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3573 - accuracy: 0.8026\n",
      "Epoch 577/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3377 - accuracy: 0.8343\n",
      "Epoch 578/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3625 - accuracy: 0.8436\n",
      "Epoch 579/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3323 - accuracy: 0.8361\n",
      "Epoch 580/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3367 - accuracy: 0.8436\n",
      "Epoch 581/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3337 - accuracy: 0.8305\n",
      "Epoch 582/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3173 - accuracy: 0.8454\n",
      "Epoch 583/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3363 - accuracy: 0.8343\n",
      "Epoch 584/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.4054 - accuracy: 0.8380\n",
      "Epoch 585/600\n",
      "537/537 [==============================] - 0s 75us/sample - loss: 0.3456 - accuracy: 0.8305\n",
      "Epoch 586/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.4057 - accuracy: 0.7952\n",
      "Epoch 587/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3751 - accuracy: 0.7989\n",
      "Epoch 588/600\n",
      "537/537 [==============================] - 0s 76us/sample - loss: 0.3326 - accuracy: 0.8380\n",
      "Epoch 589/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3297 - accuracy: 0.8399\n",
      "Epoch 590/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3295 - accuracy: 0.8417\n",
      "Epoch 591/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3670 - accuracy: 0.8156\n",
      "Epoch 592/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3208 - accuracy: 0.8473\n",
      "Epoch 593/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3290 - accuracy: 0.8324\n",
      "Epoch 594/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3347 - accuracy: 0.8231\n",
      "Epoch 595/600\n",
      "537/537 [==============================] - 0s 71us/sample - loss: 0.3449 - accuracy: 0.8305\n",
      "Epoch 596/600\n",
      "537/537 [==============================] - 0s 65us/sample - loss: 0.3201 - accuracy: 0.8399\n",
      "Epoch 597/600\n",
      "537/537 [==============================] - 0s 73us/sample - loss: 0.3202 - accuracy: 0.8343\n",
      "Epoch 598/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.3185 - accuracy: 0.8399\n",
      "Epoch 599/600\n",
      "537/537 [==============================] - 0s 67us/sample - loss: 0.4062 - accuracy: 0.8324\n",
      "Epoch 600/600\n",
      "537/537 [==============================] - 0s 69us/sample - loss: 0.3320 - accuracy: 0.8399\n"
     ]
    }
   ],
   "source": [
    "network = model.fit(X_train, Y_train, epochs=600, batch_size=120)#the batch size is the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model_1.fit(X_train,Y_train,epochs=100, test_data =(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:: 0.6753247\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,Y_test,verbose=0)\n",
    "print(\"test_acc::\",test_acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Saving our modelÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('diabetes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('diabetes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
